%%
%% Copyright 2007, 2008, 2009 Elsevier Ltd
%%
%% This file is part of the 'Elsarticle Bundle'.
%% ---------------------------------------------
%%
%% It may be distributed under the conditions of the LaTeX Project Public
%% License, either version 1.2 of this license or (at your option) any
%% later version.  The latest version of this license is in
%%    http://www.latex-project.org/lppl.txt
%% and version 1.2 or later is part of all distributions of LaTeX
%% version 1999/12/01 or later.
%%
%% The list of all files belonging to the 'Elsarticle Bundle' is
%% given in the file `manifest.txt'.
%%

%% Template article for Elsevier's document class `elsarticle'
%% with numbered style bibliographic references
%% SP 2008/03/01

\documentclass[preprint,12pt, a4paper]{elsarticle}

%% Use the option review to obtain double line spacing
%% \documentclass[authoryear,preprint,review,12pt]{elsarticle}

%% For including figures, graphicx.sty has been loaded in
%% elsarticle.cls. If you prefer to use the old commands
%% please give \usepackage{epsfig}

%% The amssymb package provides various useful mathematical symbols
\usepackage{amssymb}
%% The amsthm package provides extended theorem environments
%% \usepackage{amsthm}

%% The lineno packages adds line numbers. Start line numbering with
%% \begin{linenumbers}, end it with \end{linenumbers}. Or switch it on
%% for the whole article with \linenumbers.
\usepackage{lineno}

\usepackage{float}
\restylefloat{table}

\journal{SoftwareX}

\begin{document}

\begin{frontmatter}

%% Title, authors and addresses

%% use the tnoteref command within \title for footnotes;
%% use the tnotetext command for theassociated footnote;
%% use the fnref command within \author or \address for footnotes;
%% use the fntext command for theassociated footnote;
%% use the corref command within \author for corresponding author footnotes;
%% use the cortext command for theassociated footnote;
%% use the ead command for the email address,
%% and the form \ead[url] for the home page:
%% \title{Title\tnoteref{label1}}
%% \tnotetext[label1]{}
%% \author{Name\corref{cor1}\fnref{label2}}
%% \ead{email address}
%% \ead[url]{home page}
%% \fntext[label2]{}
%% \cortext[cor1]{}
%% \address{Address\fnref{label3}}
%% \fntext[label3]{}

\title{Sparse Distributed Memory}

%% use optional labels to link authors explicitly to addresses:
%% \author[label1,label2]{}
%% \address[label1]{}
%% \address[label2]{}

\author{Marcelo Salhab Brogliato}
\author{Alexandre Linhares}

\address{Getulio Vargas Foundation}

\begin{abstract}
%% Text of abstract
Ca. 100 words

\end{abstract}

\begin{keyword}
%% keywords here, in the form: keyword \sep keyword
Theoretical Neuroscience \sep Artificial Intelligence \sep Machine Learning \sep Memory \sep Cognitive Science

%% PACS codes here, in the form: \PACS code \sep code

%% MSC codes here, in the form: \MSC code \sep code
%% or \MSC[2008] code \sep code (2000 is the default)

\end{keyword}

\end{frontmatter}

\section*{Required Metadata}
\label{}
ı
\section*{Current code version}
\label{}

Ancillary data table required for subversion of the codebase. Kindly replace examples in right column with the correct information about your current code, and leave the left column as it is.

\begin{table}[H]
\begin{tabular}{|l|p{6.5cm}|p{6.5cm}|}
\hline
\textbf{Nr.} & \textbf{Code metadata description} & \textbf{Please fill in this column} \\
\hline
C1 & Current code version & v.1.6 \\
\hline
C2 & Permanent link to code/repository used for this code version & $https://github.com/msbrogli/sdm-framework/releases/tag/v1.6$ \\
\hline
C3 & Code Ocean compute capsule & ????????? For example: $https://codeocean.com/2017/07/30/neurospeech-colon-an-open-source-software-for-parkinson-apos-s-speech-analysis/code$\\
\hline
C4 & Legal Code License   & GPL-2.0 \\
\hline
C5 & Code versioning system used & git \\
\hline
C6 & Software code languages, tools, and services used & C, python, OpenCL, Docker \\
\hline
C7 & Compilation requirements, operating environments & python (anaconda), , libbsd \\
\hline
C8 & If available Link to developer documentation/manual & For example: $https://buildmedia.readthedocs.org/media/pdf/sdm-framework/stable/sdm-framework.pdf$ \\
\hline
C9 & Support email for questions & linhares@sdm.ai \\
\hline
\end{tabular}
\caption{Code metadata (mandatory)}
\label{}
\end{table}


\linenumbers

%% main text

The permanent link to code/repository or the zip archive should include the following requirements:

README.txt and LICENSE.txt.

Source code in a src/ directory, not the root of the repository.

Tag corresponding with the version of the software that is reviewed.

Documentation in the repository in a docs/ directory, and/or READMEs, as appropriate.




\section{Motivation and significance}
\label{}

Sparse Distributed Memory (SDM) \citep{Kanerva1988} (see also \citep{denning_sparse_1989,  flynn_sparse_1989, kanerva_sparse_1993, kanerva_parallel_1985, goos_binary_1996, kanerva_hyperdimensional_2009,  keeler_comparison_1988, rwcp_fully_1997, marinaro_spatter_1994, sahlgren_permutations_nodate, uesaka_foundations_2001}) is a mathematical model of long-term memory that has a number of neuroscientific and psychologically plausible dynamics. This model is used in all sort of applications due to its incredible ability to closely reflect the human capacity to remember past experiences from the subtlest of clues. Applications range from call admission control \citep{kwon_atm_1998, hee-yong_kwon_atm_1997}, to behavior-based robotics \citep{Rajesh1998, mendes2008robot, jockel_sparse_2009}, to noise filtering \citep{meng_modified_2009}, among others.  To understand the breadth of topics that SDM encompasses, consider the following questions:

\begin{enumerate}
    \item Why are most concepts orthogonal, unrelated to each other?
    \item Why is there Miller's magic number, i.e., we can't hold too many things in mind at once?
    \item Why do we at times instantly recall an experience; other times we can't recall anything at all; and still other times we get into this strange tip-of-the-tongue situation... the memory is clearly `there'... but remains innacessible.
    \item How does this recall process work?  What is remembering?
    \item Why do neurons die and we still remember most everything?
    \item What do neurons actually do?  What is their primary function?
\end{enumerate}

While these implementations are extremely interesting, they do not afford the flexibility to experiment that software does:

\begin{enumerate}
    \item The original 1989 hardware implementation developed in NASA by \citet{flynn_sparse_1989};

    \item a 1995 LISP implementation for the Connection Machine by \citet{turk_kanervas_1995};

    \item a 1992 APL implementation by \citet{surkan_wsdm:_1992};

    \item a 2004 FPGA implementation by \citet{silva_reconfigurable_2004};

    \item a 2005 C++ implementation by \citet{berchtold_processing_2005} from Lancaster University, in the `CommonSense ToolKit' (CSTK) \citep{noauthor_cstk:_nodate} for realtime sensor data includes SDM as one of its classification algorithms;

    \item  a 2015 `C Binary Vector Symbols (CBVS)':  includes SDM implementation as a part of  vector symbolic architecture developed by \citet{emruli_vector_2015} from EISLAB at Luleå University of Technology \footnote{The code is available at http://pendicular.net/cbvs.php};

    \item a 2013 Java implementation `Learning Intelligent Distribution Agent' (LIDA) developed by \citep{franklin_lida:_2014, snaider_integer_2013, snaider_modular_2014} Stan Franklin's group from the University of Memphis includes implementation. \footnote{http://ccrg.cs.memphis.edu/framework.html; see also http://ccrg.cs.memphis.edu/projects.html where they link to a github repository.};

\end{enumerate}

Let us analyze these.  The Connection Machine is obsolete.  The NASA implementation is hardware-based and obsolete.  APL, while reasonably influential, is not a mainstream language in science.

The FPGA implementation by \citet{silva_reconfigurable_2004} has yielded a fast scan of hard locations at low energy costs, provided one has access to the proper hardware. Their article claims a four-fold speedup over assembly language; but it does not deal with parallel processing details.  For example, it is unclear whether there was more than a single thread running on the software implementation.  Note that the framework presented here is also able to reconfigure field-programmable gate arrays, through the OpenCL heterogeneous computing platform ability to interface with Hardware Description Language and hence, reconfigure FPGAs \citep{waidyasooriya2018design, czajkowski_opencl_2012} for our tasks.

Then there is LIDA --- a whole cognitive architecture based on Hofstadter's Fluid Concepts, Kanerva's SDM, and other ideas \citep{Anwar2003, snaider_integer_2013, snaider_modular_2014, franklin_lida:_2014}.  It is developed in Java; which makes it difficult to connect to the lowest levels of hardware; to connect to GPUs or FPGAs, and to other languages --- at least in comparison to the combination Python and OpenCL proposed here\footnote{Python is sometimes called a `glue language'. That is, in my opinion, not the best metaphor.  A glue connects two things leaving an inflexible structure.  Python is perhaps best described as the interstate highway system of Programming; if something is out there, there is a way to reach it with Python.  In the comparison with Java, for instance, take the $popcnt(xor(b_i,b_j))$ operation, executed billions of times in SDM. How easy is it to program that for a particular GPU or FPGA with Java?}.  It has a non-standard license, strange to the open-source community, \emph{the LIDA Framework Software NonExclusive, Non-Commercial Use License}.  We have not found any parallelism in their code \citep{ccrg_ccrg_nodate}, which may make simulations slow or unfeasible. Moreover, potential contributors must sign an ``Agreement Regarding Contributory Code for the LIDA Framework Software''... \emph{`before Memphis can accept it'} \footnote{What they are attempting to do with this bureaucracy remains unclear, the history of computing has not been kind to those who favored centralization \citep{ferguson_computer_2002}.  We certainly refrain from contributing given the legal uncertainties of non-standard licenses and dubious processes --- even as we would like to link these libraries}.

The closest implementations to ours, in philosophy at least, is the one in `the common sense toolkit'. It is executed in C++, with a normal open-source license, and hosted on an open-source code repository.  It is, however, strikingly dissimilar to ours on the following aspects:

\begin{enumerate}
    \item SDM is but a part of the system; the description of the system reads that cstk is `A toolkit for processing and visualising sensor data in real time with support for use with embedded platforms.'

    \item The whole SDM code is composed of 143 \emph{lines} of C++ in the $cstk/cstk-devonly/sdm$ folder.

    \item There is no work on making the system parallel.

    \item There is strong coupling between location address and location data, which makes experimentation hard.

    \item There are no tests or examples to be found instantly.

    \item Finally, the last commit to this repository seems to have been made in 2005?

    \item There are no publishable or published scientific applications or experiments available to be reproduced at installation time.

    \item there is no tutorial, installation instructions, performance benchmarks, framework validation or SDM Documentation.

\end{enumerate}

Note that all these criticisms apply to the implementations in both the `common sense toolkit' and the `C Binary Vector Symbols' \citep{berchtold_processing_2005, noauthor_cstk:_nodate, emruli_vector_2015}.  While these implementations have around 150 lines of C++; at last count, the \emph{documentation of our implementation} had \emph{over 100 pages} \citep{linhares_sparse_2018}: they have aimed at running code, and we aim at improving a community and industry standard.

There is obviously a demand for use of SDM; but each group has been tied to their own \emph{ad-hoc} needs, and there has not been the emergence of a community centered on a tool. It is our belief that a tool such as standard open-source framework could bring orders of magnitude more researchers and attention if they were able to use the model, at zero cost, with an easy to use high-level language such as Python, in an intuitive platform such as Juypyter notebooks. Neuroscientists interested in long-term memory storage should not have to worry about high-bandwidth vector parallel computation.  This new tool would provide a ready to use system in which experiments could be executed almost as soon as designed --- and provide the needed replication of studies \citep{shen2014interactive}.

The main contribution of this work is a reference implementation which yields (i) orders of magnitude gains in performance, (ii) has several backends\footnote{CPUs, GPUs, FPGAs} and operations, (iii) is fully validated against the mathematical model, (iv) is cross-platform\footnote{Unix, Linux, MacOs, Windows, Amazon Web Services, etc.}, and (v) is easily extensible to test new research ideas --- and to let others replicate the studies.

Another issue is \emph{extensibility}: Extensions of SDM have been used in many applications. For example, \citet{Snaider2011} extended SDM to store sequences of vectors and trees efficiently.  \citet{Rajesh1998} used a modified SDM in an autonomous robot. \citet{Meng2009} modified SDM to clean patterns from noisy inputs. \citet{fan1997genetic} extended SDM with genetic algorithms. \citet{chada2016you} extended SDM creating the Rotational Sparse Distributed Memory (RSDM), which models network motifs, dynamic flexibility, and hierarchical organization --- reflecting results from the neuroscience literature.

Our reference implementation may, hopefully, accelerate research into the model's dynamics and make it easier for readers to replicate any previous results and easily understand the source-code of the model.  Moreover, it is compatible with Jupyter notebook and researchers may share their notebooks possibly accelerating the advances in their fields \citep{shen2014interactive}.

Other contributions have also been introduced, which include (i) a noise filtering approach, (ii) a supervised classification algorithm, (iii) and a reinforcement learning algorithm, all of them using only the original SDM proposed by Kanerva, i.e., with no additional mechanisms, algorithms, data structures, etc. Although some of these applications have already been explored in previous work \citep{Meng2009, fan1997genetic, rao1995natural}, all of them have adapted SDM to fit their problems, and none of them have used just the ideas introduced by Kanerva. We have presented different approaches with no adaptations whatsoever.

Finally, I have striven to provide a visual tour of the theory and application of SDM: whenever possible, detailed figures should tell the story --- or at least do the heavy lifting. In this study, we will see an anomaly in one of Kanerva's predictions, which I believe is related to SDM capacity. We will see tests of a generalized reading operation proposed by Physics Professor Paulo Murilo (personal communication).  We will see what happens when neurons --- and all their information --- is simply and suddenly lost.  We will see whether information-theory can improve some of Kanerva's ideas.  From (basic) noise filtering to learning to play tic-tac-toe, we will review the entirety of Dr. Pentti Kanerva's proposal.




\section{Software description}
\label{}

Describedddddd the software in as much as is necessary to establish a vocabulary needed to explain its impact.

\subsection{Software Architecture}
\label{}

Give a short overview of the overall software architecture; provide a pictorial component overview or similar (if possible). If necessary provide implementation details.

\subsection{Software Functionalities}
\label{}

Present the major functionalities of the software.

\subsection{Sample code snippets analysis (optional)}
\label{}

\section{Illustrative Examples}
\label{}

Provide at least one illustrative example to demonstrate the major functions.

Optional: you may include one explanatory video that will appear next to your article, in the right hand side panel. (Please upload any video as a single supplementary file with your article. Only one MP4 formatted, with 50MB maximum size, video is possible per article. Recommended video dimensions are 640 x 480 at a maximum of 30 frames/second. Prior to submission please test and validate your .mp4 file at $ http://elsevier-apps.sciverse.com/GadgetVideoPodcastPlayerWeb/verification$. This tool will display your video exactly in the same way as it will appear on ScienceDirect.).

\section{Impact}
\label{}

\textbf{This is the main section of the article and the reviewers weight the description here appropriately}

Indicate in what way new research questions can be pursued as a result of the software (if any).

Indicate in what way, and to what extent, the pursuit of existing research questions is improved (if so).

Indicate in what way the software has changed the daily practice of its users (if so).

Indicate how widespread the use of the software is within and outside the intended user group.

Indicate in what way the software is used in commercial settings and/or how it led to the creation of spin-off companies (if so).

\section{Conclusions}
\label{}

Set out the conclusion of this original software publication.

\section{Conflict of Interest}
Please select the appropriate text:

Potential conflict of interest exists:
We wish to draw the attention of the Editor to the following facts, which may be considered as potential conflicts of interest, and to significant financial contributions to this work. The nature of potential conflict of interest is described below: [Describe conflict of interest]

No conflict of interest exists:
We wish to confirm that there are no known conflicts of interest associated with this publication and there has been no significant financial support for this work that could have influenced its outcome.


\section*{Acknowledgements}
%\label{}

Optionally thank people and institutes you need to acknowledge.

%% The Appendices part is started with the command \appendix;
%% appendix sections are then done as normal sections
%% \appendix

%% \section{}
%% \label{}

%% References:
%% If you have bibdatabase file and want bibtex to generate the
%% bibitems, please use
%%


%% else use the following coding to input the bibitems directly in the
%% TeX file.



\begin{thebibliography}
\bibliographystyle{elsarticle-num}
\bibliography{../mybib02}

\end{thebibliography}

\section*{Current executable software version}
\label{}

Ancillary data table required for sub version of the executable software: (x.1, x.2 etc.) kindly replace examples in right column with the correct information about your executables, and leave the left column as it is.

\begin{table}[!h]
\begin{tabular}{|l|p{6.5cm}|p{6.5cm}|}
\hline
\textbf{Nr.} & \textbf{(Executable) software metadata description} & \textbf{Please fill in this column} \\
\hline
S1 & Current software version & For example 1.1, 2.4 etc. \\
\hline
S2 & Permanent link to executables of this version  & For example: $https://github.com/combogenomics/$ $DuctApe/releases/tag/DuctApe-0.16.4$ \\
\hline
S3 & Legal Software License & List one of the approved licenses \\
\hline
S4 & Computing platforms/Operating Systems & For example Android, BSD, iOS, Linux, OS X, Microsoft Windows, Unix-like , IBM z/OS, distributed/web based etc. \\
\hline
S5 & Installation requirements \& dependencies & \\
\hline
S6 & If available, link to user manual - if formally published include a reference to the publication in the reference list & For example: $http://mozart.github.io/documentation/$ \\
\hline
S7 & Support email for questions & \\
\hline
\end{tabular}
\caption{Software metadata (optional)}
\label{}
\end{table}

\end{document}
\endinput
%%
%% End of file `SoftwareX_article_template.tex'.
